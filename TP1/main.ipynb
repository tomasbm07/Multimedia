{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "from scipy.fftpack import dct\n",
    "from scipy.fftpack import idct\n",
    "import PIL as p\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns an array of type:\n",
    " - [x, y] for grayscale images\n",
    " - [x, y, [R, G, B]] for RGB images\n",
    " - [x, y, [R, G, B, A]] for RGBA images\n",
    "\"\"\"\n",
    "def read_image(filename):\n",
    "    img = image.imread(filename)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.2 função para criar colormap entre duas cores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funcao para criar um colormap;\n",
    "Parametros:\n",
    "            1.cmin-> tuplo com valores (r,g,b) minimos\n",
    "            2.cmax-> tuplo com valores (r,g,b) maximos\n",
    "Devolve o objeto correspondente ao colormap\n",
    "\"\"\"\n",
    "def create_colormap(cmin : tuple[float], cmax: tuple[float]):\n",
    "    return clr.LinearSegmentedColormap.from_list('', [cmin, cmax], N=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.3 Função para visualizar a imagem com um certo colormap*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Função para mostrar uma imagem. Aceita um colormap definido pelo utilizador ou os do matplotlib\n",
    "\"\"\"\n",
    "    \n",
    "def show_image(img, colormap = None):    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    \n",
    "    # Imagens com apenas uma coponenete: R, G, B ou Grayscale\n",
    "    if len(img.shape) == 2:\n",
    "        plt.imshow(img, cmap = colormap)\n",
    "    else:\n",
    "        if colormap != None:\n",
    "            new_img = img[:, :, 0]\n",
    "            plt.imshow(new_img, cmap = colormap)\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Semana 1\n",
    "Na diretória imagens estão presentes as imagens jpeg com baixa, média e alta qualidade, de acordo com o nome das pastas\n",
    "> - Análise da compressão das várias imagens em jpeg\n",
    "> - Converter a imagem de RGB para YCbCr\n",
    "> - *Padding* da imagen para ficar um múltiplo de 16x16\n",
    " \n",
    "\n",
    "\n",
    "## 3.1 Leitura da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_image('imagens/peppers.bmp')\n",
    "#img = read_image('imagens/barn_mountains.bmp')\n",
    "#img = read_image('imagens/logo.bmp')\n",
    "\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Tamanho dos ficheiros .bmp\n",
    "\n",
    "|        | Barn | Peppers | Logo |\n",
    "|:------:|:----:|:-------:|:----:|\n",
    "|  size  |   356.5KB  |    589.9KB   |   421.6KB  |\n",
    "\n",
    "<br>\n",
    "Foi utilizado o *Adobe Photoshop 2019* para comprimir as imagens.\n",
    "<br>\n",
    "\n",
    "### Tamanho dos ficheiros após compressão para JPEG\n",
    "\n",
    "|        | Barn | Peppers | Logo |\n",
    "|:------:|:----:|:-------:|:----:|\n",
    "|   Low  |   43.4KB  |    35.2KB    |   21.9KB  |\n",
    "| Medium |   51.5KB  |    41.3KB    |   23.1KB  |\n",
    "|  High  |   67.5KB  |    57.7KB    |   27.3KB  |\n",
    "\n",
    "<br>\n",
    "\n",
    "### Rácio de compressão\n",
    "\n",
    "|        | Barn | Peppers | Logo |\n",
    "|:------:|:----:|:-------:|:----:|\n",
    "|   Low  |   8.2:1  |    16.7:1    |   19.3:1  |\n",
    "| Medium |   6.9:1  |    14.3:1    |   18.3:1  |\n",
    "|  High  |   5.2:1  |    10.2:1    |   15.4:1  |\n",
    "\n",
    "<br>\n",
    "\n",
    "### Diferenças subjetivas jpeg/bmp\n",
    "\n",
    "|        | Barn                 | Peppers | Logo |\n",
    "|:------:|:------------------:|:--------------:|:-----------------:|\n",
    "|   Low  | não muito evidente | muito evidente     | evidente      |\n",
    "| Medium | nada evidente      | não muito evidente | evidente      |\n",
    "|  High  | nada evidente      | nada evidente      | nada evidente |\n",
    "\n",
    "## Comparação dos resultados \n",
    "A compressão é maior em imagens cujos pixels adjacentes têm uma cor semelhante. <br>\n",
    "Isto sugere que o codec do Jpeg utiliza compressão baseada em adjacência.\n",
    "\n",
    "Visualmente, notam-se maiores diferenças em locais onde há alterações bruscas na cor do pixel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = image.imread('imagens/Low/peppers.jpg')\n",
    "low.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = image.imread('imagens/Medium/peppers.jpg')\n",
    "medium.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColorMaps\n",
    "cm_gray = clr.LinearSegmentedColormap.from_list('gray', [(0,0,0), (1, 1, 1)], N = 256)\n",
    "cm_red = clr.LinearSegmentedColormap.from_list('red', [(0,0,0), (1, 0, 0)], N = 256)\n",
    "cm_green = clr.LinearSegmentedColormap.from_list('green', [(0,0,0), (0, 1, 0)], N = 256)\n",
    "cm_blue = clr.LinearSegmentedColormap.from_list('blue', [(0,0,0), (0, 0, 1)], N = 256)\n",
    "\n",
    "\n",
    "# Adaptado de https://jakevdp.github.io/PythonDataScienceHandbook/04.07-customizing-colorbars.html\n",
    "cmap = plt.cm.get_cmap(cm_gray)\n",
    "gray = cmap(np.arange(cmap.N))\n",
    "\n",
    "cmap = plt.cm.get_cmap(cm_red)\n",
    "red = cmap(np.arange(cmap.N))\n",
    "\n",
    "cmap = plt.cm.get_cmap(cm_green)\n",
    "green = cmap(np.arange(cmap.N))\n",
    "\n",
    "cmap = plt.cm.get_cmap(cm_blue)\n",
    "blue = cmap(np.arange(cmap.N))\n",
    "\n",
    "fig, ax = plt.subplots(4, figsize=(10, 5),subplot_kw=dict(xticks=[], yticks=[]))\n",
    "ax[0].imshow([gray], extent=[0, 10, 0, 1])\n",
    "ax[1].imshow([red], extent=[0, 10, 0, 1])\n",
    "ax[2].imshow([green], extent=[0, 10, 0, 1])\n",
    "ax[3].imshow([blue], extent=[0, 10, 0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Função para separar imagem nos seus componentes R, G, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Separar uma imagem RGB nos seus componentes\n",
    "\"\"\"\n",
    "def separate_components(img):\n",
    "    r = img[:, :, 0]\n",
    "    g = img[:, :, 1]\n",
    "    b = img[:, :, 2]\n",
    "    \n",
    "    return r, g, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Visualização da imagem nos seus componentes R, G, B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = separate_components(img)\n",
    "show_image(r, cm_red)\n",
    "show_image(g, cm_green)\n",
    "show_image(b, cm_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Juntar as coponentes R, G e B para formar uma imagem\n",
    "\"\"\"\n",
    "def join_components(r, g, b):\n",
    "    return np.dstack((r, g, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = join_components(r, g, b)\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Função para padding da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recebe uma imagem e altera as suas dimensões (m,n) para (16*p, 16*q).\n",
    "Isto é realizado através da cópia da ultima coluna/linha até atingir o valor multiplo de 16.\n",
    "Conta o numero de linhas/colunas adicionadas, (x,y) : 0<=x,y<=15.\n",
    "Devolve um tuplo com as dimensoes incrementadas (x,y) e a imagem com as novas dimensoes (16*p, 16*q)\n",
    "\"\"\"\n",
    "def padding(img : np.array):\n",
    "    img = img.copy()\n",
    "    shape = img.shape\n",
    "    \n",
    "    x,y = (16-img.shape[0]%16)%16, (16-img.shape[1]%16)%16\n",
    "    h_padding = np.repeat(img[-1:,:,:], x, axis = 0)\n",
    "    img = np.concatenate((img, h_padding), axis = 0)\n",
    "\n",
    "    v_padding = np.repeat(img[:,-1:,:], y, axis = 1)\n",
    "    img = np.concatenate((img, v_padding), axis = 1)\n",
    "    return shape, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recebe uma imagem e as dimensoes originais dela.\n",
    "Faz slice da imagem, elimando todos os elementos incrementados no padding;\n",
    "Devolve a imagem original\n",
    "\"\"\"\n",
    "def unpad(img : np.array, shape):\n",
    "    img = img.copy()\n",
    "    x,y,z = shape\n",
    "    img = img[:x, :y]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img)\n",
    "shape, pad_img = padding(img)\n",
    "show_image(pad_img)\n",
    "unpad_img = unpad(img, shape)\n",
    "show_image(unpad_img)\n",
    "\n",
    "# Verificação que fica igual ao original\n",
    "print(np.all(np.equal(img, unpad_img)))\n",
    "\n",
    "print(f\"Original shape: {img.shape}\")\n",
    "print(f\"Padding shape: {pad_img.shape}\")\n",
    "print(f\"After Padding and Unpadding shape: {unpad_img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Função de conversão RGB para YCbCr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Converte imagem no formato RGB para imagem no formato yCbCr;\n",
    "\"\"\"\n",
    "def rgb_to_ycbcr(img : np.array):\n",
    "    img.copy().astype(float)\n",
    "    \n",
    "    y_cb_cr_mat = np.array([ [0.299    , 0.587    , 0.114    ]\n",
    "                            ,[-0.168736, -0.331264, 0.5      ]\n",
    "                            ,[0.5      , -0.418688, -0.081312] ], dtype=float)\n",
    "    \n",
    "    y  = y_cb_cr_mat[0,0] * img[:,:,0] + y_cb_cr_mat[0,1] * img[:,:,1] + y_cb_cr_mat[0,2]*img[:,:,2]\n",
    "    cb = y_cb_cr_mat[1,0] * img[:,:,0] + y_cb_cr_mat[1,1] * img[:,:,1] + y_cb_cr_mat[1,2]*img[:,:,2] + 128\n",
    "    cr = y_cb_cr_mat[2,0] * img[:,:,0] + y_cb_cr_mat[2,1] * img[:,:,1] + y_cb_cr_mat[2,2]*img[:,:,2] + 128\n",
    "    \n",
    "    y_cb_cr = np.dstack((y, cb, cr))\n",
    "    return y_cb_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Converte imagem no formato YCbCr para imagem no formato RGB\n",
    "\"\"\"\n",
    "def ycbcr_to_rgb(img : np.array):\n",
    "    img = img.copy().astype(float)\n",
    "    \n",
    "    y_cb_cr_mat_inv = np.linalg.inv(\n",
    "                                np.array([ [0.299    , 0.587    , 0.114    ]\n",
    "                                        ,  [-0.168736, -0.331264, 0.5      ]\n",
    "                                        ,  [0.5      , -0.418688, -0.081312] ], dtype=float)\n",
    "                                    )\n",
    "    y = img[:, :, 0]\n",
    "    cb = img[:, :, 1] - 128\n",
    "    cr = img[:, :, 2] - 128\n",
    "    \n",
    "    r = y + y_cb_cr_mat_inv[0,2]*cr\n",
    "    g = y + y_cb_cr_mat_inv[1,1]*cb + y_cb_cr_mat_inv[1,2]*cr\n",
    "    b = y + y_cb_cr_mat_inv[2,1]*cb\n",
    "    \n",
    "    rgb = np.dstack((r,g,b))\n",
    "    rgb = np.round(rgb)\n",
    "    rgb[rgb > 255] = 255\n",
    "    rgb[rgb < 0] = 0\n",
    "    \n",
    "    return rgb.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycbcr = rgb_to_ycbcr(pad_img)\n",
    "rgb = ycbcr_to_rgb(ycbcr)\n",
    "\n",
    "# Verificação que fica igual ao original\n",
    "#print(np.all(np.equal(img, rgb)))\n",
    "\n",
    "show_image(img)\n",
    "show_image(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método do colormap para representar os canais Cb e Cr:\n",
    "# https://stackoverflow.com/questions/28638848/displaying-y-cb-and-cr-components-in-matlab\n",
    "\n",
    "cm_cb = clr.LinearSegmentedColormap.from_list('cb', [(0.5, 0.5, 0), (0.5, 0.5, 1)], N = 256)\n",
    "cm_cr = clr.LinearSegmentedColormap.from_list('cr', [(0, 0.5, 0.5), (1, 0.5, 0.5)], N = 256)\n",
    "\n",
    "cmap = plt.cm.get_cmap(cm_cb)\n",
    "cm_cb_rep = cmap(np.arange(cmap.N))\n",
    "\n",
    "cmap = plt.cm.get_cmap(cm_cr)\n",
    "cm_cr_rep = cmap(np.arange(cmap.N))\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(10, 2),subplot_kw=dict(xticks=[], yticks=[]))\n",
    "ax[0].imshow([cm_cb_rep], extent=[0, 10, 0, 1])\n",
    "ax[1].imshow([cm_cr_rep], extent=[0, 10, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, cb, cr = separate_components(ycbcr)\n",
    "\n",
    "show_image(y, cm_gray)\n",
    "show_image(cb, cm_cb)\n",
    "show_image(cr, cm_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=3,ncols=2,figsize=(12,12))\n",
    "\n",
    "ax[0,0].imshow(y, cm_gray)\n",
    "ax[0,1].imshow(r, cm_red)\n",
    "\n",
    "ax[1,0].imshow(cb, cm_cb)\n",
    "ax[1,1].imshow(g, cm_green)\n",
    "\n",
    "ax[2,0].imshow(cr, cm_cr)\n",
    "ax[2,1].imshow(b, cm_blue)\n",
    "for i in ax.flatten():\n",
    "    i.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica-se que o canal Y da imagem tem muito mais definição do que o Cb e do que o Cr. <br><br>\n",
    "\n",
    "Em relação aos canais R,G e B, os canais R e G são os que apresentam maior semelhança visual com o canal Y. O canal G é o que tem mais peso no calculo do canal Y, seguido do R e finalmente do B.\n",
    "\n",
    "Isto deve-se ao facto dos niveis de luminância ser maior precisamente nos canais G, seguido do R, seguido do B. <br>\n",
    "Com isto, concentra-se a maior parte da informação da luminância num dos canais, e informação sobre a crominância, que é menos importante para o olho humano nos outros (Cb e Cr). <br><br>\n",
    "\n",
    "Isto permite que haja maior compressão nos canais Cb e Cr, pois esta informação afeta menos a perceção do olho humano.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Semana 2\n",
    "Aplicação dos primeiros passos destrutivos do CODEC jpeg\n",
    "> - *Downsample* com os rácios 4:2:2 e 4:2:0 \n",
    "> - DCT aplicada á imagem toda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def sub_sample(y, cb, cr, downsample_ratio):\n",
    "    y = y.copy()\n",
    "    cb = cb.copy().astype(float)\n",
    "    cr = cr.copy().astype(float)\n",
    "    if downsample_ratio == (4,2,0):\n",
    "        ratio = round(downsample_ratio[0]/downsample_ratio[1])\n",
    "        cb = cb[::ratio,::ratio]\n",
    "        cr = cr[::ratio,::ratio]\n",
    "    else:\n",
    "        v_ratio = round(downsample_ratio[0]/downsample_ratio[1])\n",
    "        h_ratio = round(downsample_ratio[0]/downsample_ratio[2])\n",
    "        \n",
    "        cb = cb[:, ::v_ratio]\n",
    "        cr = cr[:, ::h_ratio]\n",
    "    return y,cb,cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "funciona em -- (4,2,0) e (4,2,2) --\n",
    "Parametros:\n",
    "            1. y --------------> matriz com os valores da luminancia Y\n",
    "            2. cb -------------> matriz downsampled de cb\n",
    "            3. cr -------------> matriz downsample de cr\n",
    "            4. upsample_ratio -> tuplo com 3 inteiros correspondentes ao ratio de downsample (Y:Cb:Cr)\n",
    "\"\"\"\n",
    "def const_up_sample(y, cb, cr, upsample_ratio):\n",
    "    y = y.copy()\n",
    "    cb = cb.copy()\n",
    "    cr = cr.copy()\n",
    "    \n",
    "    cbArr = np.zeros(shape = y.shape, dtype=float)\n",
    "    crArr = np.zeros(shape = y.shape, dtype=float)\n",
    "    \n",
    "    if upsample_ratio[-1] == 0:\n",
    "        ratio = int(upsample_ratio[0]/upsample_ratio[1])\n",
    "        \n",
    "        cbArr[::ratio,::ratio] = cb\n",
    "        cbArr[1::ratio,::ratio] = cb\n",
    "        cbArr[::ratio,1::ratio] = cb\n",
    "        cbArr[1::ratio,1::ratio] = cb\n",
    "        \n",
    "        crArr[::ratio,::ratio] = cr\n",
    "        crArr[1::ratio,::ratio] = cr\n",
    "        crArr[::ratio, 1::ratio] = cr\n",
    "        crArr[1::ratio,1::ratio] = cr\n",
    "        \n",
    "    else:\n",
    "        cb_ratio = int(upsample_ratio[0]/upsample_ratio[1])\n",
    "        cr_ratio = int(upsample_ratio[0]/upsample_ratio[2])\n",
    "        \n",
    "        cbArr[:,::cb_ratio] = cb\n",
    "        cbArr[:,1::cb_ratio] = cb\n",
    "        \n",
    "        crArr[:,::cr_ratio] = cr\n",
    "        crArr[:,1::cr_ratio] = cr\n",
    "        \n",
    "    return y,cbArr,crArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "funciona em -- (4,2,0) e (4,2,2) --\n",
    "Parametros:\n",
    "            1. y --------------> matriz com os valores da luminancia Y\n",
    "            2. cb -------------> matriz downsampled de cb\n",
    "            3. cr -------------> matriz downsample de cr\n",
    "            4. upsample_ratio -> tuplo com 3 inteiros correspondentes ao ratio de downsample (Y:Cb:Cr)\n",
    "\"\"\"\n",
    "def linear_up_sample(y, cb, cr, upsample_ratio):\n",
    "    y = y.copy()\n",
    "    cb = cb.copy()\n",
    "    cr = cr.copy()\n",
    "    \n",
    "    new_cb = np.zeros(shape = y.shape, dtype=float)\n",
    "    new_cr = np.zeros(shape = y.shape, dtype=float)\n",
    "    \n",
    "    if upsample_ratio[2] == 0:\n",
    "        ratio = int(upsample_ratio[0]/upsample_ratio[1])\n",
    "        #--------------------Cb interpolation----\n",
    "        cb_cols_mean = (cb[:,:-1] + np.roll(cb, -1, 1)[:,:-1])//2\n",
    "        cb_cols_mean = np.concatenate((cb_cols_mean, cb[:,-1:]), axis = 1)\n",
    "\n",
    "        new_cb[::2,::2] = cb\n",
    "        new_cb[::2,1::2] = cb_cols_mean\n",
    "\n",
    "        cb = new_cb[::2]\n",
    "        \n",
    "        cb_lines_mean = (cb[:-1] + np.roll(cb, -1, 0)[:-1])//2\n",
    "        cb_lines_mean = np.concatenate((cb_lines_mean, cb[-1:]), axis = 0)\n",
    "\n",
    "        new_cb[1::2,:] = cb_lines_mean\n",
    "        \n",
    "        #------------------------Cr interpolation----\n",
    "        cr_cols_mean = (cr[:,:-1] + np.roll(cr, -1, 1)[:,:-1])//2\n",
    "        cr_cols_mean = np.concatenate((cr_cols_mean, cr[:,-1:]), axis = 1)\n",
    "\n",
    "        new_cr[::2,::2] = cr\n",
    "        new_cr[::2,1::2] = cr_cols_mean\n",
    "\n",
    "        cr = new_cr[::2]\n",
    "        \n",
    "        cr_lines_mean = (cr[:-1] + np.roll(cr, -1, 0)[:-1])//2\n",
    "        cr_lines_mean = np.concatenate((cr_lines_mean, cr[-1:]), axis = 0)\n",
    "\n",
    "        new_cr[1::2,:] = cr_lines_mean\n",
    "        \n",
    "    else:\n",
    "        cb_ratio = int(upsample_ratio[0]/upsample_ratio[1])\n",
    "        cr_ratio = int(upsample_ratio[0]/upsample_ratio[2])\n",
    "        \n",
    "        cb_mean = (cb[:,:-1] + np.roll(cb, -1, 1)[:,:-1])/2\n",
    "        cb_mean = np.concatenate((cb_mean, cb[:,-1:]), axis = 1)\n",
    "        new_cb[:,::cb_ratio] = cb\n",
    "        new_cb[:,1::cb_ratio] = cb_mean\n",
    "        \n",
    "        cr_mean = (cr[:,:-1] + np.roll(cr, -1, 1)[:,:-1])/2\n",
    "        cr_mean = np.concatenate((cr_mean, cr[:,-1:]), axis = 1)\n",
    "        new_cr[:,::cr_ratio] = cr\n",
    "        new_cr[:,1::cr_ratio] = cr_mean\n",
    "    \n",
    "    return y,new_cb, new_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (4, 2, 2)\n",
    "y_d, cb_d, cr_d = sub_sample(y, cb, cr, ratio)\n",
    "\n",
    "show_image(y_d, cm_gray)\n",
    "show_image(cb_d, cm_cb)\n",
    "show_image(cr_d, cm_cr)\n",
    "\n",
    "print(\"Y shape: \" + str(y_d.shape), \n",
    "      \"Cb shape: \" + str(cb_d.shape), \n",
    "      \"Cr shape: \" + str(cr_d.shape), \n",
    "      sep = '\\n'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (4, 2, 0)\n",
    "y_d, cb_d, cr_d = sub_sample(y, cb, cr, ratio)\n",
    "\n",
    "show_image(y_d, cm_gray)\n",
    "show_image(cb_d, cm_cb)\n",
    "show_image(cr_d, cm_cr)\n",
    "\n",
    "print(\"Y shape: \" + str(y_d.shape), \n",
    "      \"Cb shape: \" + str(cb_d.shape), \n",
    "      \"Cr shape: \" + str(cr_d.shape), \n",
    "      sep = '\\n'\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Análise da aplicação do *downsample*\n",
    "\n",
    "No downsampling 4:2:2, há uma redução do número de pixeis, nos canais Cb e Cr, de 2:1. No caso do 4:2:0, a taxa de compressão é maior, pois é de 4:1 nesses mesmos canais. <br>\n",
    "\n",
    "Esta etapa de downsampling é destrutiva, pelo que a contrapartida é que quanto mais alta for a compressão, mais alta é a taxa de destrutividade, pois quantos mais dados forem eliminados, menos fiel vai ser a reconstrução (tendo em conta os nosso preditores). <br>\n",
    "\n",
    "Assim, a escolha destas métricas deve ter em conta a qualidade que se pretende obter na reconstrução da imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 DCT transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct_(a):\n",
    "    return dct(dct(a, norm=\"ortho\").T, norm = \"ortho\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 DCT reverse transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idct_(a_dct):\n",
    "    return idct(idct(a_dct, norm='ortho').T, norm='ortho').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCT aplicada na imagem toda\n",
    "\n",
    "y_dct = dct_(y_d)\n",
    "cb_dct = dct_(cb_d)\n",
    "cr_dct = dct_(cr_d)\n",
    "\n",
    "show_image(np.log(np.abs(y_dct) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cb_dct) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cr_dct) + 0.0001), cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverso da DCT\n",
    "\n",
    "y_idct = idct_(y_dct)\n",
    "cb_idct = idct_(cb_dct)\n",
    "cr_idct = idct_(cr_dct)\n",
    "\n",
    "show_image(y_idct, cm_gray)\n",
    "show_image(cb_idct, cm_gray)\n",
    "show_image(cr_idct, cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstrução com copia da coluna da esquerda\n",
    "\n",
    "y, cb, cr = const_up_sample(y_idct, cb_idct, cr_idct, ratio)\n",
    "\n",
    "show_image(y, cm_gray)\n",
    "show_image(cb, cm_gray)\n",
    "show_image(cr, cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Recontrução com interpolação linear (média) da coluna anterior e seguinte\n",
    "\n",
    "y, cb, cr = linear_up_sample(y_idct, cb_idct, cr_idct, ratio)\n",
    "\n",
    "show_image(y, cm_gray)\n",
    "show_image(cb, cm_gray)\n",
    "show_image(cr, cm_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.3 Potencial de Compressão\n",
    "\n",
    "A DCT, tal como a DFT, permite representar um sinal por valores de frequência com coeficientes associados. No entanto, a DCT tem a vantagem de conseguir concentrar muito mais a energia. <br>\n",
    "\n",
    "No caso, a DCT faz uma transformação do domínio do espaço para o domínio da frequência. Nesta transformação, os coeficientes das baixas frequências ficam presentes no canto superior esquerdo e os das altas frequências, no canto inferior direito. <br>\n",
    "\n",
    "Normalmente, no amplo espaço de uma imagem há vários tipos de transições, abruscas e suaves. Como é visivel em todas as imagens não há uma concentração de energia notória na DCT das imagens. Aliás, a matriz resultante demonstra-se semelhante ao ruído branco, que tem uma baixa taxa de compressão. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Semana 3\n",
    "Aplicação da DCT em blocos 8x8 ou 64x64\n",
    "> - DCT em blocos e inverso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.1 Dct in blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct_n_blocks(y, cb, cr, step):\n",
    "    dct_y = np.zeros(y.shape)\n",
    "    dct_cb = np.zeros(cb.shape)\n",
    "    dct_cr = np.zeros(cr.shape)\n",
    "    \n",
    "    for i in range(0, y.shape[0], step):\n",
    "        for j in range(0, y.shape[1], step):\n",
    "            dct_y[i:i+step, j:j+step] = dct_(y[i:i+step, j:j+step])\n",
    "    \n",
    "    for i in range(0, cb.shape[0], step):\n",
    "        for j in range(0, cb.shape[1], step):\n",
    "            dct_cb[i:i+step, j:j+step] = dct_(cb[i:i+step, j:j+step])\n",
    "            dct_cr[i:i+step, j:j+step] = dct_(cr[i:i+step, j:j+step])\n",
    "            \n",
    "    return dct_y, dct_cb, dct_cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.1 Reverse DCT in blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idct_n_blocks(y, cb, cr, step):\n",
    "    idct_y = np.zeros(y.shape)\n",
    "    idct_cb = np.zeros(cb.shape)\n",
    "    idct_cr = np.zeros(cr.shape)\n",
    "    \n",
    "    for i in range(0, y.shape[0], step):\n",
    "        for j in range(0, y.shape[1], step):\n",
    "            idct_y[ i : i+step, j:j+step] = idct_(y[i:i+step, j:j+step])\n",
    "    \n",
    "    for i in range(0, cb.shape[0], step):\n",
    "        for j in range(0, cb.shape[1], step):\n",
    "            idct_cb[ i : i+step, j : j+step] = idct_(cb[ i : i+step, j : j+step])\n",
    "            idct_cr[ i : i+step, j : j+step] = idct_(cr[ i : i+step, j : j+step])\n",
    "            \n",
    "    return idct_y, idct_cb, idct_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCT em blocos\n",
    "\n",
    "n = 8\n",
    "y_dctn, cb_dctn, cr_dctn = dct_n_blocks(y, cb, cr, n)\n",
    "\n",
    "show_image(np.log(np.abs(y_dctn) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cb_dctn) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cr_dctn) + 0.0001), cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverter DCT em blocos\n",
    "\n",
    "y_d, cb_d, cr_d = idct_n_blocks(y_dctn, cb_dctn, cr_dctn, n)\n",
    "\n",
    "show_image(y_d, cm_gray)\n",
    "show_image(cb_d, cm_gray)\n",
    "show_image(cr_d, cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "y_dctn, cb_dctn, cr_dctn = dct_n_blocks(y, cb, cr, n)\n",
    "\n",
    "show_image(np.log(np.abs(y_dctn) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cb_dctn) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cr_dctn) + 0.0001), cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d, cb_d, cr_d = idct_n_blocks(y_dctn, cb_dctn, cr_dctn, n)\n",
    "\n",
    "show_image(y_d, cm_gray)\n",
    "show_image(cb_d, cm_gray)\n",
    "show_image(cr_d, cm_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.3/7.3.2 DCT aplicada a blocos 8x8 e 64x64\n",
    "\n",
    "A aplicação da DCT por bloco parte do princípio que num pequeno espaço da imagem, a variação vai ser muito baixa. <br>\n",
    "\n",
    "Ao contrário do que aconteceu no cenário anterior, em que foi aplicada a DCT em toda a imagem, no caso da aplicação da DCT em blocos 8x8 é clara a concentração da energia em cada bloco, o que aumenta o potencial de compressão. <br>\n",
    "No caso da transformada aplicada a blocos 64x64, também é visível a concentração da energia, mas não tanto como no caso 8x8. É visível, em cada bloco, algo semelhante a ruído branco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Semana 4\n",
    "Quantização da imagem e compressão dos coponentes DC da DCT com *delta encoding*\n",
    "> - Quantização dos canais Y, Cb e Cr com as matrizes adequadas\n",
    "> - *delta encoding* para as componentes DC da DCT.\n",
    ">   - A compressão dos componentes AC não faz parte deste trabalho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Quantização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Qs():\n",
    "    Q_y = np.array(\n",
    "        [\n",
    "            [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "            [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "            [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "            [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "            [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "            [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "            [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "            [72, 92, 95, 98, 112, 100, 103, 99],\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    Q_CbCr = np.array(\n",
    "        [\n",
    "            [17, 18, 24, 47, 99, 99, 99, 99],\n",
    "            [18, 21, 26, 66, 99, 99, 99, 99],\n",
    "            [24, 26, 56, 99, 99, 99, 99, 99],\n",
    "            [47, 66, 99, 99, 99, 99, 99, 99],\n",
    "            [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "            [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "            [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "            [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "        ]\n",
    "    )\n",
    "    return Q_y, Q_CbCr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantitization(y, cb, cr, fator):\n",
    "    q_y, q_cbcr = get_Qs()\n",
    "    y_q = np.zeros(y.shape)\n",
    "    cb_q = np.zeros(cb.shape)\n",
    "    cr_q = np.zeros(cr.shape)\n",
    "    \n",
    "    if fator>=50:\n",
    "        s = (100-fator)/50\n",
    "    else:\n",
    "        s = 50/fator\n",
    "    \n",
    "    if s!=0:\n",
    "        q_y = np.round(s*q_y)\n",
    "        q_cbcr = np.round(s*q_cbcr)\n",
    "    else:\n",
    "        q_y[::,::] = 1\n",
    "        q_cbcr[::,::] = 1\n",
    "    \n",
    "    q_y[q_y>255] = 255    \n",
    "    q_cbcr[q_cbcr>255] = 255\n",
    "    \n",
    "    for r in range(0,y.shape[0],8):\n",
    "        for c in range(0,y.shape[1],8):\n",
    "            y_q[r:r+8, c:c+8] = y[ r : r+8, c : c+8] / q_y\n",
    "            \n",
    "    for r in range(0, cb.shape[0], 8):\n",
    "        for c in range(0,cb.shape[1], 8):\n",
    "            cb_q[ r : r+8, c : c+8] = cb[ r : r+8, c : c+8] / q_cbcr\n",
    "            cr_q[ r : r+8, c : c+8] = cr[ r : r+8, c : c+8] / q_cbcr\n",
    "    \n",
    "    y_q = np.round(y_q)\n",
    "    cb_q = np.round(cb_q)\n",
    "    cr_q = np.round(cr_q)\n",
    "    return y_q, cb_q, cr_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantitization_inverse(y, cb, cr, fator):\n",
    "    q_y, q_cbcr = get_Qs()\n",
    "    y_q = np.zeros(y.shape, dtype=float)\n",
    "    cb_q = np.zeros(cb.shape, dtype= float)\n",
    "    cr_q = np.zeros(cr.shape, dtype=float)\n",
    "    \n",
    "    if fator>=50:\n",
    "        s = (100-fator)/50\n",
    "    else:\n",
    "        s = 50/fator\n",
    "    \n",
    "    if s!=0:\n",
    "        q_y = np.round(s*q_y)\n",
    "        q_cbcr = np.round(s*q_cbcr)\n",
    "    else:\n",
    "        q_y[::,::] = 1\n",
    "        q_cbcr[::,::] = 1\n",
    "    \n",
    "    q_y[ q_y > 255 ] = 255    \n",
    "    q_cbcr[ q_cbcr > 255 ] = 255\n",
    "    \n",
    "    for r in range(0, y.shape[0], 8):\n",
    "        for c in range(0, y.shape[1], 8):\n",
    "            y_q[ r : r+8, c : c+8] = y[ r : r+8, c : c+8]*q_y\n",
    "            \n",
    "    for r in range(0, cb.shape[0], 8):\n",
    "        for c in range(0, cb.shape[1], 8):\n",
    "            cb_q[ r : r+8, c : c+8] = cb[ r : r+8, c : c+8] * q_cbcr\n",
    "            cr_q[ r : r+8, c : c+8] = cr[ r : r+8, c : c+8] * q_cbcr\n",
    "    \n",
    "    y_q = np.round(y_q)\n",
    "    cb_q = np.round(cb_q)\n",
    "    cr_q = np.round(cr_q)\n",
    "    return y_q, cb_q, cr_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fator de qualidade para a quantização da imagem\n",
    "\n",
    "fator = 100\n",
    "y_dctn_q, cb_dctn_q, cr_dctn_q = quantitization(y_dctn, cb_dctn, cr_dctn, fator)\n",
    "y_dctn_qi, cb_dctn_qi, cr_dctn_qi = quantitization_inverse(y_dctn_q, cb_dctn_q, cr_dctn_q, fator)\n",
    "\n",
    "show_image(np.log(np.abs(y_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cb_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cr_dctn_q) + 0.0001), cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fator de qualidade para a quantização da imagem\n",
    "\n",
    "fator = 75\n",
    "y_dctn_q, cb_dctn_q, cr_dctn_q = quantitization(y_dctn, cb_dctn, cr_dctn, fator)\n",
    "y_dctn_qi, cb_dctn_qi, cr_dctn_qi = quantitization_inverse(y_dctn_q, cb_dctn_q, cr_dctn_q, fator)\n",
    "\n",
    "show_image(np.log(np.abs(y_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cb_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cr_dctn_q) + 0.0001), cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fator de qualidade para a quantização da imagem\n",
    "\n",
    "fator = 50\n",
    "y_dctn_q, cb_dctn_q, cr_dctn_q = quantitization(y_dctn, cb_dctn, cr_dctn, fator)\n",
    "y_dctn_qi, cb_dctn_qi, cr_dctn_qi = quantitization_inverse(y_dctn_q, cb_dctn_q, cr_dctn_q, fator)\n",
    "\n",
    "show_image(np.log(np.abs(y_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cb_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cr_dctn_q) + 0.0001), cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fator de qualidade para a quantização da imagem\n",
    "\n",
    "fator = 25\n",
    "y_dctn_q, cb_dctn_q, cr_dctn_q = quantitization(y_dctn, cb_dctn, cr_dctn, fator)\n",
    "y_dctn_qi, cb_dctn_qi, cr_dctn_qi = quantitization_inverse(y_dctn_q, cb_dctn_q, cr_dctn_q, fator)\n",
    "\n",
    "show_image(np.log(np.abs(y_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cb_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cr_dctn_q) + 0.0001), cm_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fator de qualidade para a quantização da imagem\n",
    "\n",
    "fator = 10\n",
    "y_dctn_q, cb_dctn_q, cr_dctn_q = quantitization(y_dctn, cb_dctn, cr_dctn, fator)\n",
    "y_dctn_qi, cb_dctn_qi, cr_dctn_qi = quantitization_inverse(y_dctn_q, cb_dctn_q, cr_dctn_q, fator)\n",
    "\n",
    "show_image(np.log(np.abs(y_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cb_dctn_q) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(cr_dctn_q) + 0.0001), cm_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Potencial de compressão em função  do fator de qualidade\n",
    "\n",
    "É possível verificar que à medida que o fator de qualidade diminuiu, também diminuiu o número de frequências que reprentam cada bloco. Em casos em que o fator é reduzido há um grande número de blocos que aparentam ser representados apenas pelo seu componente DC. <br>\n",
    "\n",
    "Com a imagem representada por um menor número de diferentes valores, o potencial de compressão aumenta, pois a distribuição dos valores diminuiu, tal como a entropia. Assim, quanto menor for o fator de qualidade, maior é o potencial de compressão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Comparação com resultados da alínea 5\n",
    "\n",
    "Na alínea 5 foi referido que o canal Y é calculado de forma a ter a maior parte da informação de luminância da imagem e que os canais Cb e Cr são calculados de modo a conterem mais informação de crominância. <br> \n",
    "Expôs-se também que a crominância tem menos relevância na perceção da imagem do olho humano, e, portanto, os canais Cb e Cr teriam mais liberdade para a perda de informação. <br>\n",
    "\n",
    "É possível notar-se em todos os exemplos que o canal Y mantem sempre mais informação que os canais Cb e Cr. Isto deve-se exatamente à tentativa de minimizar a perda de informação de luminância na compressão destrutiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 DPCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta encoding aplicado aos coeficientes DC da DCT em blocos\n",
    "\n",
    "def diff(bloco):\n",
    "    x, y = bloco.shape\n",
    "    bloco = bloco.flatten().astype(float)\n",
    "    bloco[1:] -= bloco[:-1]\n",
    "    return bloco.reshape(x,y)\n",
    "\n",
    "def DPCM(y,cb,cr):\n",
    "\n",
    "    yBlocks = y.copy()\n",
    "    cbBlocks = cb.copy()\n",
    "    crBlocks = cr.copy()\n",
    "    \n",
    "    yBlocks[::8,::8] = diff(y[::8,::8])\n",
    "    cbBlocks[::8,::8] = diff(cb[::8,::8])\n",
    "    crBlocks[::8,::8] = diff(cr[::8,::8])\n",
    "        \n",
    "    return yBlocks, cbBlocks, crBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_reverse(bloco):\n",
    "    x, y = bloco.shape\n",
    "    bloco = bloco.flatten().astype(float)\n",
    "    for i in range(1,bloco.shape[0]):\n",
    "        bloco[i] = bloco[i] + bloco[i-1]\n",
    "    return bloco.reshape(x,y)\n",
    "\n",
    "def DPCM_reverse(yBlocks, cbBlocks, crBlocks):\n",
    "    y = yBlocks.copy()\n",
    "    cr = crBlocks.copy()\n",
    "    cb = cbBlocks.copy()\n",
    "    \n",
    "    y[::8,::8] = diff_reverse(yBlocks[::8,::8])\n",
    "    cr[::8,::8] = diff_reverse(crBlocks[::8,::8])\n",
    "    cb[::8,::8] = diff_reverse(cbBlocks[::8,::8])\n",
    "    \n",
    "    return y, cb, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d_y, d_cb, d_cr = DPCM(y_dctn_q, cb_dctn_q, cr_dctn_q)\n",
    "id_y, id_cb, id_cr = DPCM_reverse(d_y, d_cb, d_cr)\n",
    "\n",
    "show_image(np.log(np.abs(d_y) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(d_cb) + 0.0001), cm_gray)\n",
    "show_image(np.log(np.abs(d_cr) + 0.0001), cm_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise sobre a aplicação da codificação DPCM\n",
    "\n",
    "Após a aplicação da codificação DPCM, o número de blocos contíguos totalmente nulos aumentou bastante. Isto potencializa a compressão de algorítmos como o RLE. <br>\n",
    "\n",
    "De notar que esta compressão não é destrutiva, pelo que este passo ajuda a compressão sem perder qualidade na reconstrução da imagem, através de um método simples de aplicar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Semana 5\n",
    "Aplicação de todas as funções criadas antriormente com os fatores de qualidade 10, 25, 50, 75, 100\n",
    "> - Cálculo das métricas de  distorção (MSE, RMSE, SNR, PSNR) para todas as imagens e fatores de qualidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(orig, compressed):\n",
    "    return np.sum(np.square(orig-compressed))/np.prod(orig.shape) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(orig, compressed):\n",
    "    return np.sqrt(MSE(orig,compressed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNR(orig, compressed):\n",
    "    P = np.sum(np.square(orig))/np.prod(orig.shape)\n",
    "    return 10*np.log10(P/MSE(orig, compressed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(orig, compressed):\n",
    "    return 10*np.log10(np.square(orig).max()/MSE(orig,compressed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Encoder and decoder functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(filename, ratio, n, factor):\n",
    "    img = read_image(filename)\n",
    "    \n",
    "    shape, pad_img = padding(img)\n",
    "    \n",
    "    ycbcr = rgb_to_ycbcr(pad_img)\n",
    "    \n",
    "    y, cb, cr = separate_components(ycbcr)\n",
    "    \n",
    "    y_d, cb_d, cr_d = sub_sample(y, cb, cr, ratio)\n",
    "    \n",
    "    y_dct, cb_dct, cr_dct = dct_n_blocks(y_d, cb_d, cr_d, n)\n",
    "    \n",
    "    y_dct_q, cb_dct_q, cr_dct_q = quantitization(y_dct, cb_dct, cr_dct, factor)\n",
    "    \n",
    "    delta_y, delta_cb, delta_cr = DPCM(y_dct_q, cb_dct_q, cr_dct_q)\n",
    "    \n",
    "    return delta_y, delta_cb, delta_cr, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(delta_y, delta_cb, delta_cr, ratio, shape, n, factor):\n",
    "    y_dct_q, cb_dct_q, cr_dct_q = DPCM_reverse(delta_y, delta_cb, delta_cr)\n",
    "    \n",
    "    y_dct, cb_dct, cr_dct = quantitization_inverse(y_dct_q, cb_dct_q, cr_dct_q, factor)\n",
    "    \n",
    "    y_idct, cb_idct, cr_idct = idct_n_blocks(y_dct, cb_dct, cr_dct, n) # DCT em blocos n x n\n",
    "    \n",
    "    #y, cb, cr = const_up_sample(y_idct, cb_idct, cr_idct, ratio) # Upsample: cópia da coluna á esquerda\n",
    "    y, cb, cr = linear_up_sample(y_idct, cb_idct, cr_idct, ratio) # Upsample: média entre o anterior e o seguinte\n",
    "    \n",
    "    ycbcr = join_components(y, cb, cr)\n",
    "    \n",
    "    img_rgb = ycbcr_to_rgb(ycbcr)\n",
    "    \n",
    "    img = unpad(img_rgb, shape)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "f = \"imagens/barn_mountains.bmp\"\n",
    "ratio = (4,2,2)\n",
    "n=8\n",
    "fator = 100\n",
    "x,y,z,shape = encoder(f,ratio,n,fator)\n",
    "img = decoder(x,y,z,ratio,shape,n,fator)\n",
    "show_image(img)\n",
    "\n",
    "print(\"MSE:\", MSE(read_image(f).astype(float), img.astype(float)),\n",
    "     \"RMSE:\", RMSE(read_image(f).astype(float), img.astype(float)),\n",
    "     \"SNR:\", SNR(read_image(f).astype(float), img.astype(float)),\n",
    "     \"PSNR:\",PSNR(read_image(f).astype(float), img.astype(float)),\n",
    "     sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imagens = ['imagens/barn_mountains.bmp', 'imagens/peppers.bmp', 'imagens/logo.bmp']\n",
    "ratio = (4,2,2)\n",
    "n = 8\n",
    "fatores = [10, 25, 50, 75, 100]\n",
    "\n",
    "\n",
    "# maybe adicionar métricas de distorção em cada subplot para cada fator de qualidade\n",
    "\n",
    "\n",
    "for a, i in enumerate(imagens):\n",
    "    print(f\"{i.split('/')[1]}\")\n",
    "    f, ax = plt.subplots(nrows = 1, ncols = 5, figsize = (20, 5))\n",
    "    \n",
    "    f.suptitle(f\"{i.split('/')[1]}\", fontsize = 16)\n",
    "    \n",
    "    for b, fa in enumerate(fatores):\n",
    "        x, y, z, shape = encoder(i, ratio, n, fa)\n",
    "        i_jpeg = decoder(x, y, z, ratio, shape, n, fa)\n",
    "\n",
    "        #shape, pad_img = padding(i_jpeg)\n",
    "        ycbcr = rgb_to_ycbcr(i_jpeg)\n",
    "        y, cb, cr = separate_components(ycbcr)\n",
    "\n",
    "        img = read_image(i)\n",
    "        #shape, pad_img = padding(img)\n",
    "        ycbcr = rgb_to_ycbcr(img)\n",
    "        y_i, cb_i, cr_i = separate_components(ycbcr)\n",
    "\n",
    "        y_new = y_i - y\n",
    "        #show_image(y_new, cm_gray)\n",
    "        ax[b].title.set_text(f\"{i.split('/')[1]}: {fa}\")\n",
    "        ax[b].imshow(y_new, cm_gray)\n",
    "        \n",
    "        print(f\"Fator de qualidade: {fa}\")\n",
    "        print(\"MSE:\", MSE(img.astype(float), i_jpeg.astype(float)),\n",
    "         \"RMSE:\", RMSE(img.astype(float), i_jpeg.astype(float)),\n",
    "         \"SNR:\", SNR(img.astype(float), i_jpeg.astype(float)),\n",
    "         \"PSNR:\",PSNR(img.astype(float), i_jpeg.astype(float)),\n",
    "        )\n",
    "    print()\n",
    "\n",
    "\n",
    "    for i in ax.flatten():\n",
    "        i.set_axis_off()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
